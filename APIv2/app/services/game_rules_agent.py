import logging
from typing import List, Dict, Any
from uuid import UUID

from openai import AsyncAzureOpenAI

from app.config import settings
from app.domain.entities.chat_message import MessageSource
from app.domain.ports.repositories.chat_message_repository import IChatMessageRepository
from app.domain.ports.repositories.game_image_repository import IGameImageRepository
from app.domain.ports.services.conversation_history_service import IConversationHistoryService
from app.domain.ports.services.game_rules_agent import (
    IGameRulesAgent,
    AgentRequest,
    AgentResponse, 
    AgentContext
)
from app.domain.ports.services.vector_search_service import (
    IVectorSearchService,
    VectorSearchRequest
)

logger = logging.getLogger(__name__)


class GameRulesAgent(IGameRulesAgent):
    """Agent IA spÃ©cialisÃ© dans les rÃ¨gles de jeux de sociÃ©tÃ© utilisant RAG multimodal"""
    
    def __init__(
        self,
        vector_search_service: IVectorSearchService,
        message_repository: IChatMessageRepository,
        image_repository: IGameImageRepository,
        conversation_history_service: IConversationHistoryService
    ):
        self.vector_search = vector_search_service
        self.message_repository = message_repository
        self.image_repository = image_repository
        self.conversation_history_service = conversation_history_service
        
        # Client Azure OpenAI pour la gÃ©nÃ©ration de rÃ©ponses
        self._chat_client = AsyncAzureOpenAI(
            api_key=settings.azure_openai_api_key,
            azure_endpoint=settings.azure_openai_endpoint,
            api_version=settings.azure_openai_vision_api_version
        )
    
    async def generate_response(self, request: AgentRequest) -> AgentResponse:
        """GÃ©nÃ¨re une rÃ©ponse Ã  partir d'une question utilisateur"""
        logger.info(f"ðŸš€ Agent dÃ©marrage - Question: '{request.user_message}', Game ID: {request.game_id}")
        
        try:
            request.validate()
            logger.info("âœ… Validation request OK")
            
            # 1. Construire le contexte avec RAG (approche simplifiÃ©e du prototype)
            logger.info("ðŸ—ï¸ Construction contexte RAG...")
            context = await self.build_context(request)
            logger.info(f"ðŸ“Š Contexte crÃ©Ã© - Sources: {len(context.vector_results) if hasattr(context, 'vector_results') else 'unknown'}")
            
            # 2. GÃ©nÃ©rer la rÃ©ponse avec GPT-4 Vision (l'agent dÃ©cidera si contexte suffisant)
            logger.info("ðŸ¤– GÃ©nÃ©ration rÃ©ponse GPT-4 Vision...")
            response_content, sources, confidence = await self._generate_with_context(context)
            logger.info(f"âœ… RÃ©ponse gÃ©nÃ©rÃ©e - Sources: {len(sources)}, Confidence: {confidence}")
            
            return AgentResponse(
                content=response_content,
                sources=sources,
                confidence=confidence,
                search_method=settings.search_method,
                reasoning=f"RÃ©ponse gÃ©nÃ©rÃ©e avec {len(sources)} source(s)"
            )
            
        except Exception as e:
            logger.error(f"ðŸ’¥ ERREUR AGENT: {str(e)}")
            logger.error(f"ðŸ’¥ Type erreur: {type(e).__name__}")
            import traceback
            logger.error(f"ðŸ’¥ Stack trace: {traceback.format_exc()}")
            
            return AgentResponse(
                content="Je rencontre un problÃ¨me technique. Peux-tu reformuler ta question ?",
                sources=[],
                confidence=0.0,
                search_method=settings.search_method,
                reasoning=f"Erreur: {str(e)}"
            )
    
    # MÃ‰THODE SUPPRIMÃ‰E: is_game_rules_question()
    # Adopte l'approche prototype : l'agent gÃ¨re naturellement le scope 
    # via son prompt systÃ¨me "ONLY USE THE DATA PROVIDED"
    
    async def build_context(self, request: AgentRequest) -> AgentContext:
        """Construit le contexte pour l'agent IA"""
        logger.info(f"ðŸ—ï¸ build_context - Game ID: {request.game_id}, Question: '{request.user_message}'")
        
        # 1. RÃ©cupÃ©rer l'historique de conversation si demandÃ©
        conversation_history = []
        if request.include_conversation_history:
            logger.info("ðŸ“œ RÃ©cupÃ©ration historique conversation...")
            try:
                messages = await self.conversation_history_service.get_conversation_history_for_agent(
                    request.conversation_id,
                    limit_messages=settings.agent_max_conversation_history
                )
                logger.info(f"ðŸ“œ Historique rÃ©cupÃ©rÃ©: {len(messages)} messages")
                
                conversation_history = [
                    f"{'Utilisateur' if msg.is_from_user() else 'Assistant'}: {msg.content}"
                    for msg in messages[-10:]  # Limiter Ã  10 derniers messages
                ]
            except Exception as e:
                logger.error(f"ðŸ’¥ Erreur historique: {str(e)}")
                raise
        
        # 2. Recherche vectorielle dans les rÃ¨gles du jeu
        logger.info(f"ðŸ” Recherche vectorielle - Game ID: {request.game_id}")
        logger.info(f"ðŸ” Config - top_k: {settings.vector_search_top_k}, seuil: {settings.vector_similarity_threshold}")
        
        try:
            search_request = VectorSearchRequest(
                game_id=request.game_id,
                query=request.user_message,
                top_k=settings.vector_search_top_k,
                similarity_threshold=settings.vector_similarity_threshold,
                include_images=True
            )
            logger.info(f"ðŸ” VectorSearchRequest crÃ©Ã©: {search_request}")
            
            search_results = await self.vector_search.search_vectors(search_request)
            logger.info(f"ðŸ” Recherche terminÃ©e - {len(search_results) if search_results else 0} rÃ©sultats")
            
        except Exception as e:
            logger.error(f"ðŸ’¥ ERREUR RECHERCHE VECTORIELLE: {str(e)}")
            logger.error(f"ðŸ’¥ Type: {type(e).__name__}")
            raise
        
        # 3. Formater les rÃ©sultats pour l'IA (architecture 3-paires)
        formatted_results = []
        for result in search_results:
            formatted_result = {
                'content': result.extracted_text,  # Contenu sÃ©lectionnÃ© selon search_method
                'similarity': result.similarity_score,
                'page': result.page_number,
                'has_image': result.has_image(),
                'image_url': result.image_url,
                'image_id': str(result.image_id) if result.image_id else None,
                'search_method': settings.search_method,  # Type de recherche utilisÃ©
                'vector_id': str(result.vector_id)
            }
            formatted_results.append(formatted_result)
        
        return AgentContext(
            game_id=request.game_id,
            conversation_history=conversation_history,
            search_results=formatted_results,
            user_question=request.user_message
        )
    
    async def _generate_with_context(self, context: AgentContext) -> tuple[str, List[MessageSource], float]:
        """GÃ©nÃ¨re une rÃ©ponse avec le contexte fourni (approche hybride)"""
        
        # 1. Si on utilise la mÃ©thode labels, rÃ©cupÃ©rer les images originales
        images_content = []
        if settings.search_method == "labels":
            logger.info("ðŸ“¸ Mode labels actif - rÃ©cupÃ©ration des images originales")
            
            # RÃ©cupÃ©rer les IDs des images trouvÃ©es
            image_ids = [r['image_id'] for r in context.search_results if r.get('image_id')]
            unique_image_ids = list(set([UUID(id) for id in image_ids if id]))  # DÃ©dupliquer
            
            logger.info(f"ðŸ“¸ {len(unique_image_ids)} images uniques Ã  rÃ©cupÃ©rer")
            
            # RÃ©cupÃ©rer les images depuis le repository
            for image_id in unique_image_ids:
                try:
                    image = await self.image_repository.get_by_id(image_id)
                    if image and image.blob_url:
                        # Pour GPT-4 Vision, on a besoin des donnÃ©es base64
                        # Ici on utilise l'URL pour simplifier (Azure blob)
                        images_content.append({
                            "type": "image_url",
                            "image_url": {"url": image.blob_url}
                        })
                        logger.info(f"ðŸ“¸ Image ajoutÃ©e: {image.original_filename}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Erreur chargement image {image_id}: {e}")
        
        # 2. Construire le prompt avec contexte
        context_text = self._build_context_prompt(context)
        
        # 3. PrÃ©parer les messages selon le mode (architecture 3-paires)
        if images_content and settings.search_method == "labels":
            # Mode hybride labels : mÃ©tadonnÃ©es JSON + images directes
            user_content = [
                {"type": "text", "text": f"""Mode de recherche: LABELS (mÃ©tadonnÃ©es JSON)

Contexte des mÃ©tadonnÃ©es trouvÃ©es:
{context_text}

Question de l'utilisateur: {context.user_question}

ANALYSE LES IMAGES FOURNIES pour rÃ©pondre Ã  cette question. Les mÃ©tadonnÃ©es ci-dessus te guident sur le contenu des images, mais base-toi principalement sur ton analyse visuelle directe des rÃ¨gles."""}
            ]
            user_content.extend(images_content)
            
            messages = [
                {"role": "system", "content": settings.agent_system_prompt},
                {"role": "user", "content": user_content}
            ]
            
            logger.info(f"ðŸ¤– Envoi Ã  GPT-4 Vision: {len(images_content)} images + contexte textuel")
        else:
            # Mode classique : OCR ou Description textuelle
            search_type_desc = {
                "ocr": "texte OCR extrait",
                "description": "descriptions visuelles",
                "labels": "mÃ©tadonnÃ©es JSON"
            }.get(settings.search_method, "contenu")
            
            messages = [
                {
                    "role": "system", 
                    "content": settings.agent_system_prompt
                },
                {
                    "role": "user",
                    "content": f"""Mode de recherche: {settings.search_method.upper()} ({search_type_desc})

Contexte des rÃ¨gles du jeu:
{context_text}

Question de l'utilisateur: {context.user_question}

RÃ©ponds en te basant uniquement sur le contexte fourni. Si tu ne trouves pas la rÃ©ponse dans le contexte, dis-le clairement."""
                }
            ]
        
        # 3. Appeler GPT-4
        try:
            response = await self._chat_client.chat.completions.create(
                model=settings.azure_openai_vision_deployment,
                messages=messages,
                temperature=0.1,  # RÃ©ponses plus dÃ©terministes pour les rÃ¨gles
                max_tokens=1000
            )
            
            response_content = response.choices[0].message.content
            
            # 4. Construire les sources
            sources = []
            for result in context.search_results:
                source = MessageSource.create(
                    vector_id=UUID(result['vector_id']),
                    similarity_score=result['similarity'],
                    content_snippet=result['content'][:200] + "..." if len(result['content']) > 200 else result['content'],
                    image_id=UUID(result.get('image_id')) if result.get('image_id') else None,
                    image_url=result.get('image_url')
                )
                sources.append(source)
            
            # 5. Calculer la confiance basÃ©e sur la similaritÃ© des sources
            if len(context.search_results) > 0:
                avg_similarity = sum(r['similarity'] for r in context.search_results) / len(context.search_results)
                confidence = min(1.0, avg_similarity * 1.2)  # Boost lÃ©ger
            else:
                avg_similarity = 0.0
                confidence = 0.1  # Confiance minimale
            
            return response_content, sources, confidence
            
        except Exception as e:
            logger.error(f"Erreur lors de la gÃ©nÃ©ration avec GPT-4: {str(e)}")
            raise
    
    def _build_context_prompt(self, context: AgentContext) -> str:
        """Construit le prompt de contexte pour l'IA (architecture 3-paires)"""
        parts = []
        
        # Historique de conversation
        if context.conversation_history:
            parts.append("=== HISTORIQUE DE LA CONVERSATION ===")
            parts.extend(context.conversation_history[-5:])  # 5 derniers Ã©changes
            parts.append("")
        
        # RÃ©sultats de recherche avec information sur le type
        if context.search_results:
            search_method = context.search_results[0].get('search_method', 'unknown') if context.search_results else 'unknown'
            method_name = {
                "ocr": "TEXTE OCR EXTRAIT",
                "description": "DESCRIPTIONS VISUELLES", 
                "labels": "MÃ‰TADONNÃ‰ES JSON"
            }.get(search_method, "RÃˆGLES")
            
            parts.append(f"=== {method_name} PERTINENTES ===")
            for i, result in enumerate(context.search_results, 1):
                parts.append(f"Source {i} (similaritÃ©: {result['similarity']:.2f}, type: {search_method}):")
                if result.get('page'):
                    parts.append(f"Page: {result['page']}")
                
                # Afficher le contenu selon le type
                if result['content']:
                    parts.append(result['content'])
                else:
                    parts.append("[Pas de contenu textuel - voir image associÃ©e]")
                    
                if result['has_image']:
                    parts.append("[Cette source contient des Ã©lÃ©ments visuels]")
                parts.append("")
        
        return "\n".join(parts)