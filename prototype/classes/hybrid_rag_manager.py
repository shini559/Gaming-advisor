import os
import json
from langchain_openai import AzureOpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.messages import HumanMessage

from classes.image_store_manager import ImageStoreManager


class HybridRAGManager:
    """RAG Hybride : m√©tadonn√©es en ChromaDB + images directes √† l'agent"""
    
    def __init__(self, settings, game_name=None):
        print("üöÄ RAG Hybride: Initialisation")
        self.settings = settings
        self.game_name = game_name or "default"
        
        # Configuration embeddings - utiliser celui des settings hybride s'il existe
        if hasattr(settings, 'hybrid_embedding_model') and settings.hybrid_embedding_model:
            try:
                self.embeddings = settings.hybrid_embedding_model
                print("‚úÖ RAG Hybride: Utilisation du mod√®le d'embedding hybride depuis settings")
            except Exception as e:
                print(f"‚ö†Ô∏è RAG Hybride: Erreur mod√®le embedding settings: {e}")
                self.embeddings = None
        else:
            # Fallback vers configuration environnement
            embeddings_deployment = os.getenv("AZURE_EMBEDDINGS_DEPLOYMENT_NAME")
            
            if embeddings_deployment:
                try:
                    self.embeddings = AzureOpenAIEmbeddings(
                        api_version="2024-12-01-preview",
                        azure_endpoint="https://gameadvisorai.openai.azure.com/",
                        api_key=os.getenv("SUBSCRIPTION_KEY"),
                        deployment=embeddings_deployment
                    )
                    print("‚úÖ RAG Hybride: Embeddings Azure configur√©s (fallback)")
                except Exception as e:
                    print(f"‚ö†Ô∏è RAG Hybride: Erreur embeddings: {e}")
                    self.embeddings = None
            else:
                print("‚ö†Ô∏è RAG Hybride: Pas de d√©ploiement embeddings configur√©")
                self.embeddings = None
        
        # Configuration ChromaDB pour m√©tadonn√©es (collection s√©par√©e)
        persist_dir = settings.params.get("chroma_persist_directory", "./chroma_db")
        
        if self.embeddings:
            try:
                collection_name = f"hybrid_metadata_{self.game_name}"
                self.vector_store = Chroma(
                    collection_name=collection_name,
                    persist_directory=persist_dir,
                    embedding_function=self.embeddings
                )
                print(f"‚úÖ RAG Hybride: ChromaDB configur√© pour m√©tadonn√©es ({persist_dir}/{collection_name})")
            except Exception as e:
                print(f"‚ö†Ô∏è RAG Hybride: Erreur ChromaDB: {e}")
                self.vector_store = None
        else:
            self.vector_store = None
        
        # Gestionnaire d'images avec nom du jeu
        self.image_store = ImageStoreManager(game_name=self.game_name)
        
        # Mod√®les hybride sp√©cifiques
        self.vision_model = settings.hybrid_vision_model
        # Utiliser l'agent principal pour toutes les m√©thodes
        self.agent_model = settings.agent_model
        
        # Fallback simulation
        self.analyzed_documents = []
    
    def process_game_document(self, images_data):
        """Traite un document : analyse vision + stockage hybride"""
        total_vision_tokens = 0
        total_embedding_tokens = 0
        
        print(f"üîÑ RAG Hybride: Traitement de {len(images_data)} images")
        
        # 1. Analyser chaque image et stocker
        stored_image_ids = []
        for img in images_data:
            # Analyse vision pour m√©tadonn√©es (r√©utilise code existant)
            page_analysis, vision_tokens = self._analyze_page(img)
            total_vision_tokens += vision_tokens
            
            # Stocker image + m√©tadonn√©es localement
            if isinstance(page_analysis, str):
                try:
                    metadata = json.loads(page_analysis)
                except:
                    metadata = {"raw_analysis": page_analysis}
            else:
                metadata = page_analysis
            
            image_id = self.image_store.store_image(img, metadata, "game_rules")
            stored_image_ids.append(image_id)
        
        # 2. Cr√©er embeddings des m√©tadonn√©es et stocker dans ChromaDB
        embedding_tokens = self._store_metadata_in_vector_db(stored_image_ids)
        total_embedding_tokens += embedding_tokens
        
        # 3. Rapport final
        total_tokens = total_vision_tokens + total_embedding_tokens
        print(f"üìä RAG HYBRIDE TOKENS: Vision={total_vision_tokens}, Embeddings={total_embedding_tokens}, Total={total_tokens}")
        print(f"üì∑ RAG Hybride: {len(stored_image_ids)} images stock√©es")
        
        return {
            "vision_tokens": total_vision_tokens,
            "embedding_tokens": total_embedding_tokens,
            "total_tokens": total_tokens,
            "stored_images": len(stored_image_ids)
        }
    
    def _analyze_page(self, image_data):
        """Analyse vision d'une page (r√©utilise logique RAGManager)"""
        print(f"üìÑ RAG Hybride: Analyse de {image_data.get('name', 'image')}")
        
        # Essayer analyse vision r√©elle
        if self.vision_model:
            try:
                prompt = self.settings.hybrid_vision_prompt

                message = HumanMessage(content=[
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{image_data['data']}"}
                    }
                ])
                
                # Estimation tokens
                prompt_tokens = len(prompt) // 4
                image_tokens = self._estimate_image_tokens(image_data['data'])
                estimated_input_tokens = prompt_tokens + image_tokens
                
                response = self.vision_model.invoke([message])
                
                output_tokens = len(response.content) // 4
                total_vision_tokens = estimated_input_tokens + output_tokens
                
                print(f"‚úÖ RAG Hybride: M√©tadonn√©es extraites ({len(response.content)} chars)")
                print(f"üí∞ Vision tokens: ‚âà{total_vision_tokens}")
                
                return response.content, total_vision_tokens
                
            except Exception as e:
                print(f"‚ùå RAG Hybride: Erreur analyse vision: {e}")
                # Fallback simulation
                pass
        
        # Simulation si vision non disponible
        simulated_metadata = {
            "game_elements": ["cartes", "jetons", "plateau"],
            "diagrams": [{"type": "tableau", "description": "Tableau de scores", "elements": ["points", "victoire"]}],
            "game_actions": ["placer", "d√©placer", "piocher"],
            "key_concepts": ["points", "tours", "victoire"],
            "sections": [{"title": "Setup", "type": "setup", "keywords": ["mise en place", "pr√©paration"]}],
            "searchable_text": f"M√©tadonn√©es simul√©es pour {image_data.get('name', 'image')}"
        }
        
        print(f"‚ö†Ô∏è RAG Hybride: M√©tadonn√©es simul√©es")
        return simulated_metadata, 0
    
    def _estimate_image_tokens(self, base64_data):
        """Estimation tokens image (r√©utilise logique existante)"""
        image_size_bytes = len(base64_data) * 3 // 4
        
        if image_size_bytes < 50000:
            return 85
        elif image_size_bytes < 200000:
            return 170
        else:
            return 255
    
    def _store_metadata_in_vector_db(self, image_ids):
        """Stocke les m√©tadonn√©es dans ChromaDB avec r√©f√©rences aux images"""
        print(f"üíæ RAG Hybride: Vectorisation m√©tadonn√©es pour {len(image_ids)} images")
        
        if self.vector_store:
            try:
                documents = []
                metadatas = []
                
                for image_id in image_ids:
                    # R√©cup√©rer m√©tadonn√©es de l'image
                    image_data = self.image_store.get_image(image_id)
                    if not image_data:
                        continue
                    
                    metadata = image_data['metadata']
                    
                    # DEBUG: Examiner les m√©tadonn√©es brutes
                    print(f"üîç METADATA DEBUG: Keys = {list(metadata.keys())}")
                    if isinstance(metadata, dict):
                        for key, value in metadata.items():
                            print(f"   {key}: {type(value)} = '{str(value)[:100]}...'")
                    
                    # Cr√©er texte searchable √† partir des m√©tadonn√©es
                    searchable_parts = []
                    
                    # V√©rifier si les m√©tadonn√©es sont du JSON mal pars√©
                    if 'raw_analysis' in metadata and isinstance(metadata.get('raw_analysis'), str):
                        raw_text = metadata['raw_analysis']
                        
                        # Nettoyer le JSON des blocs markdown
                        if raw_text.startswith('```json'):
                            # Supprimer ```json au d√©but et ``` √† la fin
                            json_start = raw_text.find('\n') + 1
                            json_end = raw_text.rfind('\n```')
                            if json_end == -1:
                                json_end = raw_text.rfind('```')
                            if json_end != -1:
                                clean_json = raw_text[json_start:json_end].strip()
                            else:
                                clean_json = raw_text[json_start:].strip()
                        elif raw_text.startswith('```'):
                            # Format ```\n{json}\n```
                            json_start = raw_text.find('\n') + 1
                            json_end = raw_text.rfind('\n```')
                            if json_end == -1:
                                json_end = raw_text.rfind('```')
                            if json_end != -1:
                                clean_json = raw_text[json_start:json_end].strip()
                            else:
                                clean_json = raw_text[json_start:].strip()
                        else:
                            clean_json = raw_text.strip()
                        
                        print(f"üßπ JSON nettoy√© ({len(clean_json)} chars): '{clean_json[:80]}...'")
                        
                        # Essayer de parser le JSON nettoy√©
                        try:
                            import json
                            parsed_metadata = json.loads(clean_json)
                            print(f"üîß JSON pars√© avec succ√®s: {list(parsed_metadata.keys())}")
                            # Remplacer metadata par les donn√©es pars√©es
                            metadata.update(parsed_metadata)
                        except json.JSONDecodeError as e:
                            print(f"‚ùå Erreur parsing JSON nettoy√©: {e}")
                            print(f"   Contenu JSON: '{clean_json[:200]}...'")
                            # Fallback : utiliser le texte brut
                            metadata['searchable_text'] = clean_json
                    
                    if 'searchable_text' in metadata:
                        searchable_parts.append(str(metadata['searchable_text']))
                    
                    if 'game_elements' in metadata and metadata['game_elements']:
                        elements = metadata['game_elements']
                        if isinstance(elements, list):
                            searchable_parts.append("√âl√©ments: " + ", ".join(elements))
                        elif isinstance(elements, str):
                            searchable_parts.append("√âl√©ments: " + elements)
                    
                    if 'key_concepts' in metadata and metadata['key_concepts']:
                        concepts = metadata['key_concepts']
                        if isinstance(concepts, list):
                            searchable_parts.append("Concepts: " + ", ".join(concepts))
                        elif isinstance(concepts, str):
                            searchable_parts.append("Concepts: " + concepts)
                    
                    if 'game_actions' in metadata and metadata['game_actions']:
                        actions = metadata['game_actions']
                        if isinstance(actions, list):
                            searchable_parts.append("Actions: " + ", ".join(actions))
                        elif isinstance(actions, str):
                            searchable_parts.append("Actions: " + actions)
                    
                    if 'sections' in metadata and metadata['sections']:
                        sections = metadata['sections']
                        if isinstance(sections, list):
                            for section in sections:
                                if isinstance(section, dict) and 'keywords' in section and section['keywords']:
                                    keywords = section['keywords']
                                    if isinstance(keywords, list):
                                        searchable_parts.append("Section: " + ", ".join(keywords))
                                    elif isinstance(keywords, str):
                                        searchable_parts.append("Section: " + keywords)
                    
                    searchable_text = " | ".join(searchable_parts)
                    
                    # DEBUG: Logs d√©taill√©s pendant l'indexation
                    print(f"üîç INDEXATION: Image {image_id}")
                    print(f"   üìù Texte searchable ({len(searchable_text)} chars): '{searchable_text[:120]}...'")
                    print(f"   üìÅ Original: {image_data.get('original_name', 'N/A')}")
                    if 'searchable_text' in metadata:
                        print(f"   üéØ Searchable direct: '{metadata['searchable_text'][:80]}...'")
                    
                    documents.append(searchable_text)
                    
                    # M√©tadonn√©es pour ChromaDB (avec r√©f√©rence image)
                    chroma_metadata = {
                        "image_id": image_id,
                        "image_path": image_data['image_path'],
                        "source": "hybrid_rag",
                        "game": self.game_name,
                        **{k: str(v) for k, v in metadata.items() if k not in ['image_id', 'image_path', 'stored_at']}
                    }
                    metadatas.append(chroma_metadata)
                
                # Estimation tokens embeddings
                total_chars = sum(len(doc) for doc in documents)
                estimated_embedding_tokens = total_chars // 4
                
                # DEBUG: V√©rification unicit√© avant stockage
                unique_docs = set(documents)
                print(f"üîç INDEXATION FINAL: {len(documents)} documents, {len(unique_docs)} uniques")
                if len(unique_docs) < len(documents):
                    print(f"‚ö†Ô∏è PROBL√àME: {len(documents) - len(unique_docs)} documents dupliqu√©s d√©tect√©s !")
                    for i, doc in enumerate(documents):
                        print(f"   Doc {i+1}: '{doc[:60]}...'")
                else:
                    print("‚úÖ Tous les documents √† indexer sont uniques")
                
                # Ajouter au vector store
                self.vector_store.add_texts(
                    texts=documents,
                    metadatas=metadatas
                )
                
                print(f"‚úÖ RAG Hybride: {len(documents)} m√©tadonn√©es vectoris√©es")
                print(f"üí∞ Embeddings tokens: ‚âà{estimated_embedding_tokens}")
                
                return estimated_embedding_tokens
                
            except Exception as e:
                print(f"‚ùå RAG Hybride: Erreur vectorisation: {e}")
                self._store_simulation(image_ids)
                return 0
        else:
            self._store_simulation(image_ids)
            return 0
    
    def retrieve_relevant_images(self, user_query, k=3):
        """Recherche images pertinentes et retourne images directes + contexte"""
        print(f"üîé RAG Hybride: Recherche pour '{user_query[:50]}...'")
        print(f"üîç DEBUG: Query compl√®te = '{user_query}'")
        
        if self.embeddings and self.vector_store:
            try:
                # V√©rifier le nombre total de documents dans la collection
                collection_count = self.vector_store._collection.count()
                print(f"üîç DEBUG: Collection contient {collection_count} documents au total")
                
                # SOLUTION CACHE: Forcer la recr√©ation du vector store pour contourner le cache LangChain
                print("üîß DEBUG: Force refresh du vector store pour √©viter le cache")
                persist_dir = self.settings.params.get("chroma_persist_directory", "./chroma_db")
                
                # Recr√©er le vector store avec les m√™mes param√®tres pour √©viter le cache
                collection_name = f"hybrid_metadata_{self.game_name}"
                fresh_vector_store = Chroma(
                    collection_name=collection_name,
                    persist_directory=persist_dir,
                    embedding_function=self.embeddings
                )
                
                # DIAGNOSTIC: V√©rifier l'embedding de la query
                print(f"üîç DEBUG: Test embedding de la query")
                try:
                    query_embedding = self.embeddings.embed_query(user_query)
                    print(f"üîç DEBUG: Query embedding g√©n√©r√©: {len(query_embedding)} dimensions, d√©but: {query_embedding[:3]}")
                except Exception as e:
                    print(f"‚ùå DEBUG: Erreur g√©n√©ration query embedding: {e}")
                
                # DIAGNOSTIC: V√©rifier le contenu de la collection
                print(f"üîç DEBUG: V√©rification contenu collection")
                try:
                    collection = fresh_vector_store._collection
                    all_docs = collection.get(limit=10)  # R√©cup√©rer plus de docs
                    print(f"üîç DEBUG: Collection a {len(all_docs['ids'])} documents")
                    
                    # V√©rifier si tous les textes sont identiques
                    unique_texts = set()
                    for i, (doc_id, doc_text, metadata) in enumerate(zip(all_docs['ids'][:5], all_docs['documents'][:5], all_docs['metadatas'][:5])):
                        print(f"üîç DEBUG: Doc {i+1}: ID={doc_id}")
                        print(f"   üìù Texte ({len(doc_text)} chars): '{doc_text[:100]}...'")
                        print(f"   üè∑Ô∏è Image ID: {metadata.get('image_id', 'N/A')}")
                        unique_texts.add(doc_text)
                    
                    print(f"üîç DEBUG: Nombre de textes uniques: {len(unique_texts)} / {len(all_docs['documents'][:5])}")
                    
                    if len(unique_texts) == 1:
                        print("‚ùå PROBL√àME IDENTIFI√â: Tous les documents ont le m√™me contenu textuel !")
                        print(f"   üìù Contenu r√©p√©t√©: '{list(unique_texts)[0][:150]}...'")
                    elif len(unique_texts) < len(all_docs['documents'][:5]):
                        print(f"‚ö†Ô∏è PROBL√àME PARTIEL: Seulement {len(unique_texts)} textes uniques sur {len(all_docs['documents'][:5])}")
                    else:
                        print("‚úÖ Les documents ont des contenus diff√©rents")
                        
                except Exception as e:
                    print(f"‚ùå DEBUG: Erreur lecture collection: {e}")
                
                # Test SANS filtre d'abord pour voir si c'est le filtre qui pose probl√®me
                print(f"üîç DEBUG: Test similarity search SANS filtre")
                similar_chunks_no_filter = fresh_vector_store.similarity_search_with_score(
                    user_query,
                    k=k
                )
                print(f"üîç DEBUG: Sans filtre: {len(similar_chunks_no_filter) if similar_chunks_no_filter else 0} chunks")
                if similar_chunks_no_filter:
                    for i, (chunk, score) in enumerate(similar_chunks_no_filter[:3], 1):
                        print(f"üîç DEBUG: Sans filtre Chunk {i} - Score: {score:.4f} - Source: {chunk.metadata.get('source', 'N/A')}")
                
                # Recherche par similarit√© dans les m√©tadonn√©es avec scores sur le store fra√Æchement cr√©√©
                print(f"üîç DEBUG: Appel similarity_search_with_score avec k={k} sur fresh store AVEC filtre")
                similar_chunks_with_scores = fresh_vector_store.similarity_search_with_score(
                    user_query,
                    k=k,  # Nombre d'images √† r√©cup√©rer
                    filter={"$and": [{"source": {"$eq": "hybrid_rag"}}, {"game": {"$eq": self.game_name}}]}
                )
                print(f"üîç DEBUG: similarity_search_with_score retourn√© {len(similar_chunks_with_scores) if similar_chunks_with_scores else 0} chunks")
                
                # Extraire les chunks et afficher les scores
                similar_chunks = []
                if similar_chunks_with_scores:
                    for i, (chunk, score) in enumerate(similar_chunks_with_scores, 1):
                        similar_chunks.append(chunk)
                        print(f"üîç DEBUG: Chunk {i} - Score: {score:.4f} - ID: {chunk.metadata.get('image_id', 'inconnu')}")
                
                if similar_chunks:
                    # Extraire les image_ids des r√©sultats
                    image_ids = [chunk.metadata.get('image_id') for chunk in similar_chunks if 'image_id' in chunk.metadata]
                    
                    # Logs d√©taill√©s des images trouv√©es
                    print(f"‚úÖ RAG Hybride: {len(similar_chunks)} m√©tadonn√©es trouv√©es")
                    for i, chunk in enumerate(similar_chunks, 1):
                        metadata = chunk.metadata
                        image_id = metadata.get('image_id', 'inconnu')
                        
                        log_info = f"üñºÔ∏è Image {i}: {image_id}"
                        if 'image_path' in metadata:
                            filename = os.path.basename(metadata['image_path'])
                            log_info += f" ({filename})"
                        
                        print(log_info)
                        
                        # Afficher les √©l√©ments de jeu d√©tect√©s
                        if 'game_elements' in metadata:
                            elements_str = metadata['game_elements']
                            if isinstance(elements_str, str) and elements_str.startswith('['):
                                try:
                                    import ast
                                    elements = ast.literal_eval(elements_str)
                                    print(f"   üéÆ √âl√©ments: {', '.join(elements[:5])}{'...' if len(elements) > 5 else ''}")
                                except:
                                    print(f"   üéÆ √âl√©ments: {elements_str[:50]}...")
                            else:
                                print(f"   üéÆ √âl√©ments: {str(elements_str)[:50]}...")
                        
                        # Afficher les concepts cl√©s
                        if 'key_concepts' in metadata:
                            concepts_str = metadata['key_concepts']
                            if isinstance(concepts_str, str) and concepts_str.startswith('['):
                                try:
                                    import ast
                                    concepts = ast.literal_eval(concepts_str)
                                    print(f"   üí° Concepts: {', '.join(concepts[:5])}{'...' if len(concepts) > 5 else ''}")
                                except:
                                    print(f"   üí° Concepts: {concepts_str[:50]}...")
                            else:
                                print(f"   üí° Concepts: {str(concepts_str)[:50]}...")
                        
                        # Aper√ßu du texte de recherche
                        searchable_preview = chunk.page_content[:80] + "..." if len(chunk.page_content) > 80 else chunk.page_content
                        print(f"   üí¨ Contexte: {searchable_preview}")
                    
                    # R√©cup√©rer les images compl√®tes
                    images = self.image_store.get_images_by_ids(image_ids)
                    
                    # Logs des images effectivement r√©cup√©r√©es
                    if images:
                        print(f"üì∑ RAG Hybride: {len(images)} images charg√©es pour l'agent")
                        for i, img in enumerate(images, 1):
                            original_name = img['metadata'].get('original_name', 'inconnu')
                            image_size = len(img['image_data']) // 1024  # Taille approximative en KB
                            print(f"   üìÑ Image {i}: {original_name} (~{image_size}KB)")
                    
                    # Formater le contexte hybride
                    context = self._format_hybrid_context(images, similar_chunks)
                    
                    return {
                        "images": images,  # Images directes pour l'agent
                        "context": context,  # Contexte textuel
                        "image_count": len(images)
                    }
                else:
                    print("‚ö†Ô∏è RAG Hybride: Aucune image pertinente trouv√©e")
                    return None
                    
            except Exception as e:
                print(f"‚ùå RAG Hybride: Erreur recherche: {e}")
                return None
        else:
            print("‚ö†Ô∏è RAG Hybride: Composants non configur√©s")
            return {"context": f"[Simulation hybride pour: {user_query[:30]}...]", "images": [], "image_count": 0}
    
    def _format_hybrid_context(self, images, chunks):
        """Formate le contexte hybride (m√©tadonn√©es + r√©f√©rences images)"""
        if not images or not chunks:
            return None
        
        context_parts = []
        for i, (image, chunk) in enumerate(zip(images, chunks), 1):
            metadata = image['metadata']
            
            context_part = f"[Image {i}] {metadata.get('original_name', 'image')}:\n"
            
            if 'game_elements' in metadata:
                context_part += f"  ‚Ä¢ √âl√©ments: {', '.join(metadata['game_elements'])}\n"
            
            if 'key_concepts' in metadata:
                context_part += f"  ‚Ä¢ Concepts: {', '.join(metadata['key_concepts'])}\n"
            
            if 'sections' in metadata and metadata['sections']:
                section_types = [s.get('type', 'g√©n√©ral') for s in metadata['sections']]
                context_part += f"  ‚Ä¢ Sections: {', '.join(set(section_types))}\n"
            
            context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def _store_simulation(self, image_ids):
        """Stockage simulation"""
        for image_id in image_ids:
            self.analyzed_documents.append({
                "image_id": image_id,
                "content": f"[M√©tadonn√©es simul√©es pour {image_id}]",
                "timestamp": "now"
            })
        print(f"üìö RAG Hybride: {len(self.analyzed_documents)} images en simulation")
    
    def clear_vector_store(self):
        """Vide le store hybride (m√©tadonn√©es + images)"""
        if self.vector_store:
            try:
                collection = self.vector_store._collection
                all_docs = collection.get()
                
                if all_docs['ids']:
                    collection.delete(ids=all_docs['ids'])
                    print(f"üóëÔ∏è RAG Hybride: {len(all_docs['ids'])} m√©tadonn√©es supprim√©es")
                else:
                    print("üóëÔ∏è RAG Hybride: Store m√©tadonn√©es d√©j√† vide")
                
                # Vider aussi les images stock√©es
                self.image_store.clear_storage("game_rules")
                
                # Vider simulation
                self.analyzed_documents = []
                
            except Exception as e:
                print(f"‚ùå RAG Hybride: Erreur vidage: {e}")
                raise e
        else:
            print("‚ö†Ô∏è RAG Hybride: Pas de store √† vider")
    
    def get_vector_store_info(self):
        """Infos sur le store hybride"""
        if self.vector_store:
            try:
                collection = self.vector_store._collection
                metadata_count = collection.count()
                
                image_info = self.image_store.get_storage_info()
                
                return {
                    "document_count": metadata_count,
                    "image_count": image_info["total_images"],
                    "store_type": "Hybrid (ChromaDB + Images)",
                    "has_documents": metadata_count > 0,
                    "storage_info": image_info
                }
            except:
                return {
                    "document_count": 0,
                    "image_count": 0,
                    "store_type": "Hybrid (ChromaDB + Images)",
                    "has_documents": False
                }
        else:
            image_info = self.image_store.get_storage_info()
            return {
                "document_count": len(self.analyzed_documents),
                "image_count": image_info["total_images"],
                "store_type": "Simulation Hybride",
                "has_documents": len(self.analyzed_documents) > 0,
                "storage_info": image_info
            }